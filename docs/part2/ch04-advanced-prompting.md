# Chapter 4: 고급 프롬프팅 기법

!!! abstract "학습 목표"
    - Few-shot Learning의 원리를 이해하고 효과적인 예시를 설계할 수 있다
    - Chain of Thought(CoT) 기법으로 복잡한 추론 문제를 해결할 수 있다
    - 역할 부여(Role-playing)의 효과와 한계를 파악할 수 있다
    - Temperature와 Top-P 파라미터를 상황에 맞게 조절할 수 있다

---

## 1. Few-shot Learning: 예시가 모델을 가르친다

### 개념 이해

!!! tip "Few-shot Learning"
    프롬프트에 **몇 가지 예시(examples)**를 포함하여 AI가 원하는 패턴을 학습하도록 유도하는 기법입니다. "이렇게 해줘"라고 설명하는 대신, "이런 식으로 해줘"라고 **보여주는** 방식입니다.

### Shot의 종류

| 유형 | 예시 수 | 설명 | 적합한 상황 |
|------|---------|------|------------|
| **Zero-shot** | 0개 | 예시 없이 지시만 제공 | 단순한 작업, 일반적 요청 |
| **One-shot** | 1개 | 하나의 예시 제공 | 형식이 명확한 작업 |
| **Few-shot** | 2~5개 | 여러 예시 제공 | 복잡한 패턴, 특정 스타일 |

### Zero-shot vs Few-shot 비교

=== "Zero-shot (예시 없음)"

    ```
    다음 문장의 감정을 분석해줘:
    "이 제품 정말 실망이에요"
    ```

    *결과: "부정적인 감정입니다" (형식 불일치 가능)*

=== "Few-shot (예시 포함)"

    ```
    다음 문장들의 감정을 분석해줘:

    문장: "오늘 날씨가 너무 좋아요!"
    감정: 긍정

    문장: "배송이 늦어서 짜증나요"
    감정: 부정

    문장: "그냥 그래요"
    감정: 중립

    문장: "이 제품 정말 실망이에요"
    감정:
    ```

    *결과: "부정" (원하는 형식 그대로)*

### Few-shot 설계 원칙

#### 1) 다양성 확보

예시가 다양한 케이스를 포함해야 합니다.

| 구분 | 나쁜 예시 (모두 비슷한 케이스) | 좋은 예시 (다양한 케이스 포함) |
|------|-------------------------------|-------------------------------|
| 예시 1 | 긍정 문장 -> 긍정 | 긍정 문장 -> 긍정 |
| 예시 2 | 긍정 문장 -> 긍정 | 부정 문장 -> 부정 |
| 예시 3 | 긍정 문장 -> 긍정 | 중립 문장 -> 중립 |
| 예시 4 | - | 혼합 문장 -> 혼합 |
| **결과** | 모델이 다양한 케이스 처리 불가 | 모델이 다양한 케이스 처리 가능 |

#### 2) 일관된 형식

모든 예시가 동일한 형식을 따라야 합니다.

| 요소 | 잘못된 예 | 올바른 예 |
|------|----------|----------|
| 구분자 | 예시마다 다른 구분자 | 모든 예시에 동일한 구분자 |
| 레이블 | "긍정", "Positive", "좋음" 혼용 | "긍정", "부정", "중립"으로 통일 |
| 순서 | 입력-출력 순서 불규칙 | 항상 입력 → 출력 순서 |

#### 3) 대표성

예시가 실제 입력과 유사해야 합니다.

!!! warning "예시 선택 주의"
    예시와 실제 입력의 **도메인, 길이, 복잡도**가 유사해야 합니다. 짧은 예시만 보여주고 긴 입력을 처리하게 하면 결과가 불안정해집니다.

### 📌 사례: Few-shot 실전 활용

#### 사례 1: 이메일 제목 생성

```
다음 이메일 본문에 적합한 제목을 생성해줘.

---
본문: 지난 회의에서 논의한 프로젝트 일정을 확정했습니다.
      다음 주 월요일 시작으로 진행하겠습니다.
제목: [확정] 프로젝트 일정 안내

---
본문: 내일 예정된 미팅이 고객 사정으로 취소되었습니다.
      추후 일정 재조정하겠습니다.
제목: [취소] 내일 미팅 일정 변경 안내

---
본문: 이번 분기 매출 보고서를 첨부합니다.
      검토 후 피드백 부탁드립니다.
제목: [검토요청] 분기 매출 보고서

---
본문: 신규 입사자 환영회를 다음 주 금요일에 진행합니다.
      많은 참석 부탁드립니다.
제목:
```

#### 사례 2: 데이터 변환

```
다음 형식으로 정보를 변환해줘:

입력: 홍길동, 서울시 강남구, 010-1234-5678
출력: {"name": "홍길동", "address": "서울시 강남구", "phone": "010-1234-5678"}

입력: 김영희, 부산시 해운대구, 010-9876-5432
출력: {"name": "김영희", "address": "부산시 해운대구", "phone": "010-9876-5432"}

입력: 이철수, 대전시 유성구, 010-5555-1234
출력:
```

---

## 2. Chain of Thought: 단계별 사고 유도

### 개념 이해

!!! tip "Chain of Thought (CoT)"
    AI에게 **"단계별로 생각해봐"**라고 요청하여 복잡한 문제를 순차적으로 풀도록 유도하는 기법입니다. 특히 **수학, 논리, 추론** 문제에서 정확도를 크게 향상시킵니다.[^1]

### CoT가 필요한 이유

| 방식 | 처리 과정 | 특징 |
|------|----------|------|
| **일반 프롬프트** | 문제 -> 답 | 중간 과정 없이 바로 답변, 오류 가능성 높음 |
| **CoT 프롬프트** | 문제 -> 단계1 -> 단계2 -> 단계3 -> 검증 -> 답 | 단계별 사고 과정을 거쳐 정확도 향상 |

### CoT 적용 방법

#### 방법 1: 명시적 요청

프롬프트에 "단계별로", "하나씩", "차근차근" 등의 표현을 추가합니다.

| 일반 프롬프트 | CoT 프롬프트 |
|--------------|-------------|
| "이 문제 풀어줘" | "이 문제를 **단계별로** 풀어줘" |
| "답을 알려줘" | "**하나씩 생각하면서** 답을 알려줘" |
| "분석해줘" | "**차근차근 분석 과정을 보여주면서** 결론을 내줘" |

#### 방법 2: "Let's think step by step"

간단하지만 강력한 트리거 문구입니다.

```
문제: 사과 3개가 있는 바구니가 4개 있습니다.
     각 바구니에서 1개씩 먹으면 남은 사과는 몇 개인가요?

Let's think step by step.
```

### Zero-shot CoT vs Few-shot CoT

=== "Zero-shot CoT"

    ```
    문제: 상점에 사과가 23개 있었습니다.
         오전에 8개를 팔고, 오후에 12개를
         더 입고했습니다. 현재 사과는?

    단계별로 풀어주세요.
    ```

=== "Few-shot CoT"

    ```
    문제: 연필이 15자루 있었는데 7자루를 사용했다.
    풀이:
    1. 처음 연필: 15자루
    2. 사용한 연필: 7자루
    3. 남은 연필: 15 - 7 = 8자루
    답: 8자루

    문제: 상점에 사과가 23개 있었습니다.
         오전에 8개를 팔고, 오후에 12개를
         더 입고했습니다. 현재 사과는?
    풀이:
    ```

### 📌 사례: CoT 적용 전후 비교

#### 사례 1: 수학 문제

| ❌ 일반 프롬프트 | ✅ CoT 프롬프트 |
|:---------------|:--------------|
| `철수는 10,000원을 가지고 있습니다. 3,500원짜리 빵 2개와 1,200원짜리 음료 3개를 샀습니다. 거스름돈은?` | `철수는 10,000원을 가지고 있습니다. 3,500원짜리 빵 2개와 1,200원짜리 음료 3개를 샀습니다. 거스름돈은? 단계별로 계산해주세요.` |
| *결과: "3,400원입니다" (오류 가능)* | *결과: 1. 빵 비용: 7,000원 → 2. 음료 비용: 3,600원 → 3. 총: 10,600원 → 4. 600원 부족* |

#### 사례 2: 논리 문제

```
문제: A, B, C, D 네 사람이 있습니다.
- A는 B보다 키가 큽니다.
- C는 D보다 키가 작습니다.
- B와 D는 키가 같습니다.
키가 가장 큰 사람은 누구인가요?

Let's think step by step.

1. A > B (A가 B보다 큼)
2. C < D (C가 D보다 작음, 즉 D > C)
3. B = D (B와 D는 같음)
4. 따라서: A > B = D > C
5. 결론: A가 가장 키가 큽니다.
```

### CoT가 효과적인 작업

| 작업 유형 | 효과 | 예시 |
|----------|------|------|
| **수학 문제** | ⭐⭐⭐⭐⭐ | 다단계 계산, 문장제 |
| **논리 추론** | ⭐⭐⭐⭐⭐ | 조건 분석, 순서 추론 |
| **의사결정** | ⭐⭐⭐⭐ | 장단점 비교, 선택 |
| **코드 디버깅** | ⭐⭐⭐⭐ | 오류 추적, 로직 분석 |
| **단순 사실 질문** | ⭐⭐ | "수도가 어디야?" 등 |

---

## 3. 역할 부여(Role-playing)의 효과와 한계

### 개념 이해

!!! tip "역할 부여(Role-playing)"
    AI에게 **특정 전문가, 캐릭터, 관점**을 부여하여 해당 역할에 맞는 응답을 유도하는 기법입니다. Chapter 3의 Persona 요소를 심화한 것입니다.

### 역할 부여의 효과

| 효과 | 설명 | 예시 |
|------|------|------|
| **톤 조절** | 응답의 어조와 스타일 변화 | 격식체 vs 친근체 |
| **관점 전환** | 특정 시각에서의 분석 | 투자자 관점, 소비자 관점 |
| **깊이 조절** | 전문성 수준 조절 | 전문가 vs 입문자 |
| **창의성 유도** | 특정 스타일의 창작 | 작가, 마케터, 디자이너 |

### 효과적인 역할 부여 패턴

#### 패턴 1: 전문가 역할

```
당신은 15년 경력의 UX 디자이너입니다.
사용자 중심 설계에 전문성을 가지고 있으며,
다양한 스타트업과 대기업에서 근무한 경험이 있습니다.

다음 앱 화면에 대해 UX 관점에서 피드백을 주세요.
```

#### 패턴 2: 다중 관점 분석

```
다음 비즈니스 아이디어에 대해 세 가지 관점에서 분석해주세요:

1. [투자자 관점]: 수익성과 시장 기회
2. [엔지니어 관점]: 기술적 실현 가능성
3. [마케터 관점]: 고객 확보 전략

아이디어: 구독 기반 건강식 배달 서비스
```

#### 패턴 3: 비평가 역할

```
당신은 엄격한 편집자입니다.
다음 글의 문제점을 날카롭게 지적하고,
구체적인 개선 방안을 제시해주세요.
좋은 점보다 개선이 필요한 점에 집중해주세요.
```

### 📌 사례: 역할 부여 Before/After

#### 사례 1: 마케팅 카피 작성

=== "역할 없음"

    ```
    새로운 운동화 광고 문구를 써줘.
    ```

    *결과: 일반적이고 평범한 문구*

=== "역할 부여"

    ```
    당신은 Nike에서 10년간 일한
    카피라이터입니다. 감성적이면서도
    행동을 유발하는 문구를 만드는
    것으로 유명합니다.

    새로운 운동화 광고 문구를 써줘.
    타겟: 20대 직장인
    핵심 메시지: 일상에서의 작은 도전
    ```

    *결과: 브랜드 톤에 맞는 감성적 카피*

#### 사례 2: 코드 리뷰

=== "역할 없음"

    ```
    이 코드 리뷰해줘.
    [코드]
    ```

    *결과: 일반적인 피드백*

=== "역할 부여"

    ```
    당신은 Google의 시니어 엔지니어입니다.
    코드 품질, 성능, 보안에 엄격한 기준을
    적용합니다.

    다음 코드를 리뷰해주세요:
    1. 버그 가능성
    2. 성능 이슈
    3. 보안 취약점
    4. 코드 스타일

    [코드]
    ```

    *결과: 체계적이고 전문적인 리뷰*

### 역할 부여의 한계

!!! danger "역할 부여의 오해"

    **역할 부여는 AI에게 실제 전문 지식을 부여하지 않습니다.**

    - ❌ "변호사 역할" → 법률 자문 대체 불가
    - ❌ "의사 역할" → 의료 진단 대체 불가
    - ❌ "재무사 역할" → 투자 조언 대체 불가

    역할 부여는 **스타일과 관점**을 조절할 뿐, **사실적 정확성**을 보장하지 않습니다.

### 역할 부여 한계 대응 전략

| 한계 | 대응 방법 |
|------|----------|
| **사실 정확성** | 중요한 정보는 반드시 팩트체킹 |
| **전문 영역** | 실제 전문가 검토 필수 |
| **법적 효력** | AI 조언에 법적 효력 없음 인지 |
| **과신 방지** | "전문가처럼 보이는" 것과 "전문가인 것"은 다름 |

---

## 4. Temperature와 Top-P 조절

### 개념 이해

!!! tip "Temperature와 Top-P"
    **Temperature**와 **Top-P**는 AI 응답의 **무작위성(randomness)**을 조절하는 파라미터입니다. 이 값을 조절하면 창의적인 응답과 일관된 응답 사이에서 균형을 맞출 수 있습니다.

### Temperature 이해

Temperature는 **0에서 2 사이**의 값으로, 응답의 무작위성을 조절합니다.

| Temperature 값 | 특성 | 적합한 용도 |
|----------------|------|------------|
| **0.0** | 결정적, 정확성 최대 | 팩트 기반 답변, 코드 생성, 데이터 추출 |
| **0.7** | 균형점, 일반 용도 | 일반 대화, 글쓰기, 요약 |
| **1.0** | 창의적, 다양성 증가 | 브레인스토밍, 창작, 아이디어 |
| **2.0** | 매우 무작위, 불안정 | 비추천 |

| Temperature | 특성 | 적합한 작업 |
|-------------|------|------------|
| **0.0~0.3** | 결정적, 일관성 높음 | 팩트 기반 답변, 코드, 데이터 처리 |
| **0.4~0.7** | 균형 | 일반 대화, 글쓰기, 요약 |
| **0.8~1.0** | 창의적, 다양성 | 브레인스토밍, 창작, 아이디어 |
| **1.0+** | 매우 무작위 | 대부분의 경우 비추천 |

### Top-P (Nucleus Sampling) 이해

Top-P는 **누적 확률 기준**으로 단어 선택 범위를 제한합니다.

| Top-P | 의미 | 효과 |
|-------|------|------|
| **0.1** | 상위 10% 확률의 단어만 선택 | 매우 보수적 |
| **0.5** | 상위 50% 확률의 단어까지 선택 | 중간 |
| **0.9** | 상위 90% 확률의 단어까지 선택 | 다양성 증가 |
| **1.0** | 모든 단어 선택 가능 | 최대 다양성 |

### Temperature vs Top-P

!!! tip "어떤 것을 조절해야 할까?"

    **일반적인 권장사항**: 둘 중 하나만 조절하세요.

    - **Temperature 조절**: 더 직관적, 대부분의 경우 충분
    - **Top-P 조절**: 더 세밀한 제어 필요 시
    - **둘 다 조절**: 예측하기 어려운 결과, 비추천

### 작업별 권장 설정

| 작업 | Temperature | Top-P | 이유 |
|------|-------------|-------|------|
| **코드 생성** | 0.0~0.2 | 0.1 | 정확성 최우선 |
| **팩트 기반 답변** | 0.0~0.3 | 0.1 | 일관성 필요 |
| **번역** | 0.3~0.5 | 0.5 | 정확성 + 자연스러움 |
| **일반 대화** | 0.7 | 0.9 | 균형 |
| **글쓰기** | 0.7~0.8 | 0.9 | 다양한 표현 |
| **브레인스토밍** | 0.9~1.0 | 0.95 | 창의성 극대화 |
| **시/소설 창작** | 0.8~1.0 | 0.9 | 예술적 표현 |

### 📌 사례: Temperature 설정 비교

```
프롬프트: "인공지능의 미래에 대해 한 문장으로 말해줘"

Temperature 0.0 (5회 실행 결과):
1. "인공지능은 인간의 삶을 혁신적으로 변화시킬 것입니다."
2. "인공지능은 인간의 삶을 혁신적으로 변화시킬 것입니다."
3. "인공지능은 인간의 삶을 혁신적으로 변화시킬 것입니다."
→ 동일한 결과 (결정적)

Temperature 0.7 (5회 실행 결과):
1. "인공지능은 우리의 일상과 산업을 근본적으로 바꿀 것입니다."
2. "AI는 의료, 교육, 환경 등 다양한 분야에서 혁신을 이끌 것입니다."
3. "인공지능과 인간의 협업이 미래 사회의 핵심이 될 것입니다."
→ 다양한 결과 (창의적)

Temperature 1.2 (5회 실행 결과):
1. "미래 인공지능은 감정 해석의 경계를 허물며 예술적 영감을..."
2. "AI 존재론적 질문이 철학과 기술의 교차점에서..."
3. "양자 신경망이 의식의 본질을 재정의하는 시대가..."
→ 불안정하고 때때로 이상한 결과
```

---

## 5. 고급 기법 조합 전략

### 기법 조합 가이드

여러 기법을 조합하면 더 강력한 결과를 얻을 수 있습니다.

| 작업 유형 | 기법 조합 순서 | 기대 결과 |
|----------|---------------|----------|
| **복잡한 분석 작업** | 역할 부여 -> Few-shot -> CoT | 최상의 결과 |
| **창의적 작업** | 역할 부여 -> Temperature 높임 | 다양한 아이디어 |
| **정확한 데이터 작업** | Few-shot -> Temperature 낮춤 | 일관된 형식 |

### 조합 예시

#### 예시 1: 역할 + Few-shot + CoT

```
[역할]
당신은 경험 많은 데이터 분석가입니다.
비즈니스 데이터를 해석하고 실행 가능한 인사이트를
도출하는 것이 전문입니다.

[Few-shot 예시]
데이터: 월별 매출이 3개월 연속 10% 하락
분석:
1. 현상: 매출 지속 감소 추세
2. 가능한 원인: 계절성, 경쟁 심화, 제품 노후화
3. 추가 확인 필요: 고객 이탈률, 경쟁사 동향
4. 권장 조치: 고객 설문, 가격 전략 재검토
결론: 즉각적인 원인 분석과 대응 필요

[실제 분석 대상]
데이터: 웹사이트 방문자는 20% 증가했으나
       구매 전환율이 5%에서 2%로 하락

분석:
```

#### 예시 2: 다중 역할 토론

```
다음 주제에 대해 두 전문가의 토론을 진행해주세요.

주제: "기업은 재택근무를 영구적으로 도입해야 하는가?"

[찬성 측: HR 전문가]
- 직원 만족도와 유연성 관점에서 주장

[반대 측: 경영 컨설턴트]
- 조직 문화와 협업 효율 관점에서 주장

각 측이 3번씩 번갈아 발언하고,
마지막에 균형 잡힌 결론을 제시해주세요.
```

---

## 6. 적용 지침

### 기법 선택 가이드

| 상황 | 추천 기법 | 이유 |
|------|----------|------|
| 특정 형식이 필요할 때 | Few-shot | 예시로 형식을 정확히 전달 |
| 복잡한 추론이 필요할 때 | CoT | 단계별 사고로 정확도 향상 |
| 특정 관점이 필요할 때 | 역할 부여 | 원하는 관점/스타일 유도 |
| 일관된 출력이 필요할 때 | Temperature ↓ | 무작위성 감소 |
| 다양한 아이디어가 필요할 때 | Temperature ↑ | 창의성 증가 |

### 자주 하는 실수

!!! danger "피해야 할 실수들"

    1. **Few-shot 예시 부족**: 1개로는 부족, 최소 2-3개 제공
    2. **예시 품질 무시**: 잘못된 예시 = 잘못된 결과
    3. **CoT 과용**: 단순 질문에 CoT 불필요
    4. **역할 과신**: 역할 부여 ≠ 전문가 대체
    5. **Temperature 극단값**: 0.0이나 2.0은 대부분 부적합

---

## 핵심 정리

!!! tip "이 챕터의 핵심 포인트"
    1. **Few-shot Learning**: 예시를 통해 원하는 패턴을 학습시킴
       - 다양성, 일관된 형식, 대표성 확보
    2. **Chain of Thought**: "단계별로 생각해봐"로 복잡한 추론 정확도 향상
       - 수학, 논리 문제에 특히 효과적
    3. **역할 부여**: 스타일과 관점을 조절하지만, 전문성을 부여하지는 않음
       - 팩트체킹 여전히 필수
    4. **Temperature**: 0(결정적) ~ 1+(창의적) 조절
       - 작업 특성에 맞게 설정
    5. **기법 조합**: 여러 기법을 조합하여 최적의 결과 도출

---

## 생각해볼 질문

!!! question "토론 질문"

    1. Few-shot 예시를 몇 개 제공하는 것이 가장 효과적일까?
    2. CoT가 효과적이지 않은 작업 유형은 무엇일까?
    3. 역할 부여의 한계를 어떻게 극복할 수 있을까?
    4. Temperature 설정의 "정답"은 있을까?

---

## 관련 위키 문서

- [Few-shot Learning](../wiki/concepts/few-shot-learning.md)
- [Chain of Thought](../wiki/concepts/chain-of-thought.md)
- [역할 부여](../wiki/concepts/role-playing.md)
- [프롬프트](../wiki/concepts/prompt.md)

---

## 참고 자료

- Wei, J. et al. (2022). *Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*. NeurIPS 2022.
- Brown, T. et al. (2020). *Language Models are Few-Shot Learners*. NeurIPS 2020.
- OpenAI. (2024). *API Reference: Temperature and Top-P*. https://platform.openai.com/docs/api-reference
---

<div class="nav-buttons">
<a href="../part2/ch03-prompt-structure/" class="nav-button nav-prev">&larr; 이전: Chapter 3: 프롬프트의 구조</a>
<a href="../part2/ch05-iteration/" class="nav-button nav-next">다음: Chapter 5: 반복 개선의 방법론 &rarr;</a>
</div>
