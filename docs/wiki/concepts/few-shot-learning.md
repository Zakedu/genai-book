# Few-shot Learning

!!! info "최종 수정일: 2025-01-15"

예시를 제공하여 AI의 응답 패턴을 유도하는 프롬프팅 기법입니다.

---

## 개념 이해

**Few-shot Learning**은 AI에게 **몇 가지 예시(shot)를 보여주고**, 그 패턴을 따라 응답하도록 유도하는 기법입니다. 마치 "이런 식으로 해줘"라고 보여주는 것과 같습니다.

### Shot의 종류

| 용어 | 예시 개수 | 설명 |
|------|----------|------|
| **Zero-shot** | 0개 | 예시 없이 직접 질문 |
| **One-shot** | 1개 | 예시 1개 제공 |
| **Few-shot** | 2~5개 | 예시 여러 개 제공 |

```
Zero-shot: "다음 문장을 요약해주세요: [문장]"

One-shot:  "예시) 원문: 오늘 날씨가 좋다 → 요약: 좋은 날씨
           다음 문장을 요약해주세요: [문장]"

Few-shot:  "예시1) 원문: ... → 요약: ...
           예시2) 원문: ... → 요약: ...
           예시3) 원문: ... → 요약: ...
           다음 문장을 요약해주세요: [문장]"
```

---

## 왜 효과적인가?

### 1. 명확한 기대 전달

AI에게 원하는 응답 형식을 정확히 보여줍니다.

=== "Zero-shot (모호함)"
    ```
    다음 리뷰가 긍정인지 부정인지 분류해주세요.
    "이 제품 정말 좋아요!"
    ```
    → AI가 "긍정입니다", "Positive", "이 리뷰는 긍정적인 감정을..." 등 다양하게 응답 가능

=== "Few-shot (명확함)"
    ```
    리뷰를 긍정/부정으로 분류합니다.

    리뷰: "배송이 너무 느려요" → 부정
    리뷰: "품질이 기대 이상이에요" → 긍정
    리뷰: "가격 대비 별로네요" → 부정

    리뷰: "이 제품 정말 좋아요!" →
    ```
    → AI가 패턴을 인식하고 "긍정"이라고 답변

### 2. 특수한 형식 학습

독특한 출력 형식도 예시로 쉽게 전달됩니다.

```
입력: 서울
출력: [도시] 서울 | [국가] 대한민국 | [대륙] 아시아

입력: 파리
출력: [도시] 파리 | [국가] 프랑스 | [대륙] 유럽

입력: 뉴욕
출력:
```

---

## 활용 패턴

### 패턴 1: 분류 작업

```markdown
다음 고객 문의를 분류해주세요.

예시:
문의: "주문한 상품이 아직 안 왔어요" → 배송
문의: "환불 처리해주세요" → 환불
문의: "이 상품 재입고 되나요?" → 재고
문의: "결제가 안 돼요" → 결제

문의: "상품이 파손되어 왔어요" →
```

### 패턴 2: 텍스트 변환

```markdown
문장을 비즈니스 이메일 톤으로 바꿔주세요.

예시:
원문: "내일 회의 가능?"
변환: "내일 회의 일정이 가능하신지 여쭙고 싶습니다."

원문: "자료 보내줘"
변환: "관련 자료를 전달해 주시면 감사하겠습니다."

원문: "검토 부탁해"
변환:
```

### 패턴 3: 데이터 추출

```markdown
텍스트에서 정보를 추출해주세요.

예시:
텍스트: "김철수(010-1234-5678)에게 연락주세요"
추출: {"이름": "김철수", "전화번호": "010-1234-5678"}

텍스트: "담당자 이영희 대리, 이메일 lee@company.com"
추출: {"이름": "이영희", "직급": "대리", "이메일": "lee@company.com"}

텍스트: "박지민 과장 (02-555-1234, park@firm.co.kr)"
추출:
```

### 패턴 4: 창작 스타일 지정

```markdown
다음 스타일로 제품 설명을 작성해주세요.

예시:
제품: 노트북 가방
설명: "출퇴근길의 든든한 파트너. 15인치 노트북도 거뜬히,
      생활방수로 갑작스런 비에도 안심. 당신의 소중한 장비를 지켜드립니다."

제품: 무선 이어폰
설명: "음악에 빠져드는 순간. 노이즈캔슬링으로 온전히 나만의 세계,
      8시간 연속 재생으로 하루종일 함께. 귀에 닿는 작은 콘서트홀."

제품: 스마트워치
설명:
```

---

## 효과적인 예시 작성법

### 1. 다양성 확보

좋은 예시는 다양한 케이스를 커버합니다.

=== "Bad (편향된 예시)"
    ```
    예시:
    "훌륭합니다" → 긍정
    "최고예요" → 긍정
    "정말 좋아요" → 긍정

    "별로네요" →
    ```
    모든 예시가 긍정이라 AI가 혼란

=== "Good (균형 잡힌 예시)"
    ```
    예시:
    "훌륭합니다" → 긍정
    "실망이에요" → 부정
    "그저 그래요" → 중립

    "별로네요" →
    ```
    다양한 케이스 포함

### 2. 일관된 형식

모든 예시는 동일한 형식을 따라야 합니다.

=== "Bad (불일치)"
    ```
    Q: 서울의 인구는? A: 약 970만명
    질문: 부산 인구 얼마야? → 340만 정도
    도쿄 인구: 1400만명입니다

    Q: 뉴욕의 인구는?
    ```

=== "Good (일관성)"
    ```
    Q: 서울의 인구는?
    A: 약 970만명

    Q: 부산의 인구는?
    A: 약 340만명

    Q: 도쿄의 인구는?
    A: 약 1400만명

    Q: 뉴욕의 인구는?
    A:
    ```

### 3. 적절한 복잡도

예시는 실제 작업과 비슷한 복잡도여야 합니다.

```markdown
# 실제 작업이 복잡한 경우, 예시도 복잡하게

예시 1:
입력: "2024년 3월 15일 오후 3시에 강남역 근처 카페에서 미팅"
출력: {
  "날짜": "2024-03-15",
  "시간": "15:00",
  "장소": "강남역 근처 카페",
  "유형": "미팅"
}

예시 2:
입력: "다음주 월요일 점심에 팀 회식"
출력: {
  "날짜": "다음주 월요일",
  "시간": "점심",
  "장소": null,
  "유형": "회식"
}
```

---

## Few-shot vs Fine-tuning

| 항목 | Few-shot Learning | Fine-tuning |
|------|-------------------|-------------|
| 데이터 필요량 | 2~10개 예시 | 수백~수천 개 |
| 준비 시간 | 즉시 | 수 시간~수일 |
| 비용 | 낮음 | 높음 |
| 유연성 | 높음 (즉시 변경) | 낮음 (재학습 필요) |
| 성능 | 좋음 | 매우 좋음 |
| 적합한 경우 | 빠른 프로토타이핑, 다양한 작업 | 특정 작업 반복, 높은 정확도 필요 |

!!! tip "실무 권장"
    대부분의 경우 Few-shot으로 시작하고, 성능이 부족할 때만 Fine-tuning을 고려하세요.

---

## 고급 기법

### Chain-of-Thought + Few-shot

예시에 추론 과정까지 포함하면 더 정확한 결과를 얻습니다.

```markdown
문제를 단계별로 풀어주세요.

예시:
Q: 가게에서 사과 3개(500원)와 배 2개(800원)를 샀다. 총액은?
A: 1단계) 사과 가격: 3 × 500 = 1,500원
   2단계) 배 가격: 2 × 800 = 1,600원
   3단계) 총액: 1,500 + 1,600 = 3,100원
   답: 3,100원

Q: 연필 5자루(200원)와 공책 3권(1,000원)을 샀다. 총액은?
A:
```

### Self-Consistency 적용

같은 문제를 여러 예시로 보여주고 일관성을 확인합니다.

```markdown
다음 문장의 감정을 분석하세요.

예시:
"오늘 정말 기분이 좋아!" → 긍정 (확신도: 높음)
"좀 아쉽긴 하지만 괜찮아" → 중립 (확신도: 중간)
"이건 정말 최악이야" → 부정 (확신도: 높음)

"나쁘지 않은 것 같기도..." →
```

---

## 주의사항

### 예시 수의 한계

- 너무 적으면: 패턴 인식 부족
- 너무 많으면: 토큰 낭비, 오히려 혼란

!!! info "권장 예시 수"
    - 간단한 분류: 2~3개
    - 복잡한 변환: 3~5개
    - 창작/스타일: 2~4개

### 예시 순서의 영향

최근 예시에 더 영향을 받을 수 있으므로, 가장 대표적인 예시를 마지막에 배치하세요.

### 편향 주의

예시가 특정 패턴에 편향되면 AI도 편향된 답변을 합니다.

---

## 관련 기법

| 기법 | 설명 | 관계 |
|------|------|------|
| [Chain of Thought](chain-of-thought.md) | 단계별 추론 | Few-shot과 결합 가능 |
| Zero-shot | 예시 없이 질문 | Few-shot의 반대 |
| In-context Learning | 맥락 내 학습 | Few-shot의 상위 개념 |

---

## 참고 자료

- Brown, T. et al. (2020). "Language Models are Few-Shot Learners"
- Liu, P. et al. (2023). "Pre-train, Prompt, and Predict: A Systematic Survey"

