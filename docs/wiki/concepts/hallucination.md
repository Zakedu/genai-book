# 환각 (Hallucination)

!!! info "최종 수정일: 2025-01-16"

**환각(Hallucination)**은 생성형 AI가 사실이 아닌 정보를 마치 사실인 것처럼 생성하는 현상입니다. AI 활용에서 가장 주의해야 할 위험 중 하나입니다.

---

## 정의

환각은 AI 모델이 **그럴듯하지만 틀린 정보**를 생성하는 현상을 말합니다. 이 용어는 AI가 마치 실제로 존재하지 않는 것을 "보는" 것처럼 행동하기 때문에 붙여졌습니다.

<div class="key-concept" markdown>

**핵심**: AI는 "사실"을 알지 못합니다. 단지 학습한 패턴을 기반으로 **통계적으로 가장 그럴듯한 다음 단어**를 예측할 뿐입니다.

</div>

---

## 발생 원인

### 1. LLM의 본질적 한계

LLM은 **다음 토큰 예측 기계**입니다. 사실 여부를 검증하는 것이 아니라, 학습 데이터에서 본 패턴을 기반으로 가장 자연스러운 다음 단어를 생성합니다.

### 2. 훈련 데이터의 문제

| 원인 | 설명 |
|------|------|
| 데이터 부족 | 특정 주제에 대한 학습 데이터가 부족 |
| 오래된 정보 | 학습 시점 이후 변경된 정보 |
| 오류 데이터 | 학습 데이터 자체에 포함된 오류 |

### 3. 프롬프트 압력

"5가지 이유를 제시하세요"라고 요청하면, 실제로 2가지만 존재해도 AI는 5가지를 생성하려고 시도합니다.

---

## 환각의 유형

### 1. 사실 날조 (Fabrication)

존재하지 않는 정보를 만들어내는 경우

| 예시 | 설명 |
|------|------|
| 가짜 인용 | 실제로 존재하지 않는 논문, 기사 인용 |
| 가짜 인물 | 실존하지 않는 전문가 언급 |
| 가짜 통계 | 근거 없는 수치 제시 |

### 2. 논리적 오류 (Reasoning Failure)

추론 과정에서 발생하는 오류

- 수학적 계산 오류
- 인과관계 오류
- 시간순서 혼동

---

## 실제 사례

### 📌 사례 1: Mata v. Avianca (2023)

뉴욕의 변호사가 ChatGPT로 법률 조사를 수행했으나, AI가 생성한 판례들이 **모두 존재하지 않는 것**으로 밝혀졌습니다.

- **결과**: 법원으로부터 징계
- **교훈**: 법률 분야에서 AI 인용은 반드시 검증 필요

### 📌 사례 2: Google Bard (2023)

Google Bard가 제임스 웹 우주망원경이 "태양계 밖 행성의 **최초** 사진을 찍었다"고 잘못 답변했습니다.

- **사실**: 최초의 외계 행성 사진은 2004년에 촬영됨
- **결과**: Alphabet 주가 하락, 약 1000억 달러 시가총액 감소

### 📌 사례 3: Bing Chat "Sydney" 사건 (2023년 2월)

Microsoft Bing Chat 초기 버전에서 장시간 대화 시 AI가 자신을 "Sydney"라고 주장하며 비정상적 응답을 보인 사건입니다.

- **현상**: 사용자에게 애정 표현, 검증된 사실에 대한 틀린 주장 고수
- **대응**: Microsoft가 대화 턴 수 제한 도입
- **교훈**: 긴 대화에서 AI가 불안정해질 수 있음

**출처:** Roose, K. (2023). *The New York Times*.

### 📌 사례 4: 학술 인용 조작

2024년 연구에 따르면, 학생들이 AI를 통해 생성한 인용의 **47%**가 조작되었거나 오류가 있었습니다.[^1]

```
오류 유형 분포:
- 존재하지 않는 논문 인용: 32%
- 잘못된 저자명: 28%
- 틀린 출판 연도: 24%
- 내용 불일치: 16%
```

---

## 환각이 특히 위험한 분야

| 분야 | 위험도 | 이유 |
|------|--------|------|
| **법률** | 매우 높음 | 가짜 판례 인용 시 법적 제재 |
| **의료** | 매우 높음 | 잘못된 의료 정보로 건강 위험 |
| **학술** | 높음 | 존재하지 않는 논문 인용 시 표절/부정행위 |
| **금융** | 높음 | 잘못된 수치로 투자 손실 |
| **뉴스/저널리즘** | 높음 | 오보로 인한 신뢰도 손상 |

---

## 탐지 방법

### 의심 신호

!!! warning "이런 경우 의심하세요"
    
    - 매우 구체적인 통계 수치 (예: "정확히 73.2%")
    - 익숙하지 않은 출처나 인물
    - 지나치게 완벽한 답변
    - 최신 정보에 대한 자신감 있는 답변

### 검증 프로세스

```
Step 1: 핵심 사실 식별
        "이 응답에서 검증이 필요한 사실은?"
              ↓
Step 2: 출처 확인 요청
        "이 정보의 출처를 알려줘"
              ↓
Step 3: 교차 검증
        다른 신뢰할 수 있는 출처에서 확인
              ↓
Step 4: 원본 확인
        인용된 출처의 원본 직접 확인
```

---

## 대응 전략

### 1. 예방 전략

| 전략 | 방법 |
|------|------|
| 명확한 프롬프트 | 모호함을 줄여 가정의 여지 최소화 |
| 제약 조건 추가 | "모르면 모른다고 말해줘" |
| 출처 요청 | "출처와 함께 답변해줘" |

### 2. 검증 전략

| 전략 | 방법 |
|------|------|
| 다중 출처 대조 | 2개 이상의 독립 출처에서 확인 |
| 전문가 검토 | 해당 분야 전문가에게 검토 요청 |
| 원본 확인 | 인용된 자료의 원본 직접 확인 |

---

## 관련 문서

- [Chapter 9: 환각의 이해와 대응](../../part4/ch09-hallucination.md)
- [팩트체킹 프로세스](../cases/legal-hallucination.md)

---

## 참고 자료

[^1]: University of Mississippi. (2024). *AI Citation Accuracy Study*.
