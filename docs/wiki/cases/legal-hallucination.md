# 법률 환각 사례: Mata v. Avianca

!!! info "최종 수정일: 2025-01-15"

AI가 생성한 가짜 판례를 인용한 법률 사건으로, AI 환각(Hallucination)의 위험성을 보여주는 대표적 사례입니다.

---

## 사건 개요

| 항목 | 내용 |
|------|------|
| 사건명 | Mata v. Avianca, Inc. |
| 법원 | 미국 뉴욕 남부 연방지방법원 |
| 시기 | 2023년 5월 |
| 핵심 쟁점 | ChatGPT가 생성한 가짜 판례 인용 |

---

## 사건 경과

### 배경

2022년, Roberto Mata는 콜롬비아 항공사 Avianca를 상대로 기내 서비스 카트에 의한 부상에 대해 소송을 제기했습니다.

### 문제 발생

1. 원고측 변호사 Steven Schwartz가 법원에 준비서면 제출
2. 준비서면에 6개의 판례 인용
3. **해당 판례들이 모두 존재하지 않는 가짜**임이 밝혀짐

### 가짜 판례 예시

변호사가 인용한 가짜 판례들:

| 인용된 판례 | 문제점 |
|-------------|--------|
| Varghese v. China Southern Airlines | 존재하지 않음 |
| Shaboon v. Egyptair | 존재하지 않음 |
| Petersen v. Iran Air | 존재하지 않음 |
| Martinez v. Delta Airlines | 존재하지 않음 |
| Estate of Durden v. KLM | 존재하지 않음 |
| Miller v. United Airlines | 존재하지 않음 |

### 발각 과정

1. 피고측 변호인이 인용된 판례를 검색했으나 찾을 수 없었음
2. 법원에 판례의 진위 확인 요청
3. 원고측 변호사에게 해명 요구
4. 변호사가 **ChatGPT를 사용해 판례를 검색했다**고 시인

---

## ChatGPT와의 대화 내용

법원 문서에 공개된 변호사와 ChatGPT의 대화:

```
변호사: "Varghese v. China Southern Airlines 판례가 실제로 존재하나요?"

ChatGPT: "네, Varghese v. China Southern Airlines Co. Ltd.,
925 F.3d 1339 (11th Cir. 2019)는 실제 판례입니다."

변호사: "Westlaw나 Lexis 같은 법률 데이터베이스에서
찾을 수 있나요?"

ChatGPT: "네, 주요 법률 데이터베이스에서 찾을 수 있습니다."
```

!!! danger "핵심 문제"
    ChatGPT는 존재하지 않는 판례에 대해 마치 실제로 존재하는 것처럼 상세한 정보(사건 번호, 법원, 연도)까지 제공했습니다.

---

## 법원의 판결

### 제재 내용

P. Kevin Castel 판사는 다음과 같은 제재를 내렸습니다:

| 제재 대상 | 내용 |
|----------|------|
| Steven Schwartz 변호사 | $5,000 벌금 |
| Peter LoDuca 변호사 | $5,000 벌금 |
| 법률 사무소 | 총 $5,000 벌금 |
| 추가 조치 | 관련 판사들에게 사과 서한 발송 |

### 판사의 언급

> "변호사에게는 법원에 제출하는 문서의 정확성을 확인할 의무가 있습니다.
> 인공지능 도구를 사용할 수 있지만, 그 결과물을 검증해야 하는 책임은
> 전적으로 변호사에게 있습니다."

---

## 교훈

### AI 사용의 한계

```
┌─────────────────────────────────────────────────┐
│              AI 환각의 특징                      │
├─────────────────────────────────────────────────┤
│ • 매우 자신감 있는 어조로 거짓 정보 제공         │
│ • 구체적인 세부사항(날짜, 번호 등) 포함          │
│ • 추가 질문에도 일관되게 거짓 정보 유지          │
│ • 사용자가 검증하지 않으면 발견 어려움           │
└─────────────────────────────────────────────────┘
```

### 전문 분야에서의 AI 활용 원칙

| 원칙 | 설명 |
|------|------|
| **검증 필수** | AI 생성 정보는 반드시 원본 출처 확인 |
| **도구로 활용** | AI는 보조 도구, 최종 판단은 전문가 |
| **책임 인식** | AI 사용 결과에 대한 책임은 사용자 |
| **한계 이해** | AI의 환각 가능성 항상 인지 |

---

## 이후 영향

### 법조계 대응

이 사건 이후 여러 법원에서 AI 사용에 관한 지침을 발표했습니다:

| 법원/기관 | 대응 |
|----------|------|
| 텍사스 북부 연방법원 | AI 생성 문서 사전 고지 의무화 |
| 뉴저지 대법원 | AI 사용 가이드라인 발표 |
| 미국변호사협회 | AI 윤리 지침 업데이트 |

### 다른 분야로의 확산

- **의료**: AI 진단 정보 검증 강화
- **학술**: AI 생성 참고문헌 검증 필수화
- **저널리즘**: AI 팩트체킹 도구 개발

---

## 예방 방법

### AI 정보 검증 체크리스트

- [ ] 인용된 출처가 실제로 존재하는지 확인
- [ ] 원본 문서/데이터베이스에서 직접 확인
- [ ] 여러 독립적인 출처와 교차 검증
- [ ] 전문가 또는 동료의 검토 요청
- [ ] AI에게 "확실한가요?"라고 재확인 (주의: 동일한 거짓 반복 가능)

### 안전한 AI 활용법

```markdown
❌ 잘못된 방법
"이 판례에 대해 알려줘" → 그대로 사용

✅ 올바른 방법
"이 주제 관련 판례 검색 키워드 추천해줘"
→ 실제 법률 데이터베이스에서 검색
→ 원본 확인 후 사용
```

---

## 관련 자료

- 사건 판결문: Mata v. Avianca, Inc., No. 22-cv-1461 (S.D.N.Y. June 22, 2023)
- 관련 개념: [환각 (Hallucination)](../../appendix/glossary.md)
- 위험 관리: [Part 4 - 위험관리](../../part4/index.md)

