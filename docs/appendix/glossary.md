# C. 용어 사전

생성형 AI 관련 한/영 용어 정리입니다.

---

## ㄱ

**강화학습 (Reinforcement Learning)**
: 보상과 벌칙을 통해 AI가 최적의 행동을 학습하는 방식

**검색 증강 생성 (RAG, Retrieval-Augmented Generation)**
: 외부 데이터베이스에서 관련 정보를 검색하여 AI 응답에 활용하는 기술

**과적합 (Overfitting)**
: AI가 학습 데이터에만 지나치게 맞춰져 새로운 데이터에서 성능이 떨어지는 현상

**그라운딩 (Grounding)**
: AI 응답을 실제 데이터나 출처에 기반하도록 하는 기법

---

## ㄴ

**노이즈 (Noise)**
: 데이터에 포함된 불필요하거나 오류가 있는 정보

---

## ㄷ

**대규모 언어 모델 (LLM, Large Language Model)**
: 방대한 텍스트 데이터로 학습된 AI 모델 (예: GPT-4, Claude, Gemini)

**데이터 증강 (Data Augmentation)**
: 기존 데이터를 변형하여 학습 데이터를 늘리는 기법

**디코더 (Decoder)**
: 트랜스포머 구조에서 출력을 생성하는 부분

---

## ㅁ

**멀티모달 (Multimodal)**
: 텍스트, 이미지, 오디오 등 여러 형태의 데이터를 함께 처리하는 능력

**메타 프롬프트 (Meta Prompt)**
: AI의 전반적인 행동 방식을 지정하는 시스템 수준의 프롬프트

---

## ㅂ

**벡터 (Vector)**
: 텍스트나 이미지를 숫자 배열로 변환한 것

**벡터 데이터베이스 (Vector Database)**
: 벡터화된 데이터를 저장하고 유사도 검색을 수행하는 데이터베이스

**베이스라인 (Baseline)**
: 비교 기준이 되는 기본 성능 수치

---

## ㅅ

**생성형 AI (Generative AI)**
: 텍스트, 이미지, 코드 등 새로운 콘텐츠를 생성하는 AI

**셀프 어텐션 (Self-Attention)**
: 입력 시퀀스 내에서 각 요소가 다른 요소들과의 관계를 계산하는 메커니즘

**시스템 프롬프트 (System Prompt)**
: AI의 역할, 성격, 제약 조건을 정의하는 프롬프트

---

## ㅇ

**에이전트 (Agent)**
: 자율적으로 작업을 수행하고 결정을 내리는 AI 시스템

**에폭 (Epoch)**
: 전체 학습 데이터를 한 번 완전히 학습하는 주기

**엔코더 (Encoder)**
: 트랜스포머 구조에서 입력을 이해하고 표현하는 부분

**임베딩 (Embedding)**
: 텍스트, 이미지 등을 고정 길이의 숫자 벡터로 변환하는 과정

---

## ㅈ

**정렬 (Alignment)**
: AI가 인간의 의도와 가치에 맞게 행동하도록 하는 것

**제로샷 (Zero-shot)**
: 예시 없이 AI가 직접 작업을 수행하는 방식

---

## ㅊ

**추론 (Inference)**
: 학습된 AI 모델이 새로운 입력에 대해 결과를 생성하는 과정

---

## ㅋ

**컨텍스트 윈도우 (Context Window)**
: AI가 한 번에 처리할 수 있는 텍스트의 최대 길이 (토큰 수로 측정)

---

## ㅌ

**토큰 (Token)**
: AI가 텍스트를 처리하는 기본 단위 (단어, 부분 단어, 문자 등)

**토크나이저 (Tokenizer)**
: 텍스트를 토큰으로 분할하는 도구

**트랜스포머 (Transformer)**
: 현대 LLM의 기반이 되는 신경망 아키텍처

---

## ㅍ

**파라미터 (Parameter)**
: AI 모델 내부의 학습 가능한 가중치 (GPT-4는 약 1.8조 개)

**파인튜닝 (Fine-tuning)**
: 사전 학습된 모델을 특정 작업에 맞게 추가 학습시키는 과정

**프롬프트 (Prompt)**
: AI에게 전달하는 입력 텍스트 또는 지시문

**프롬프트 엔지니어링 (Prompt Engineering)**
: 원하는 결과를 얻기 위해 프롬프트를 최적화하는 기술

**퓨샷 (Few-shot)**
: 몇 가지 예시를 제공하여 AI의 응답 패턴을 유도하는 기법

---

## ㅎ

**하이퍼파라미터 (Hyperparameter)**
: 모델 학습 과정을 제어하는 설정값 (학습률, 배치 크기 등)

**할루시네이션/환각 (Hallucination)**
: AI가 사실이 아닌 정보를 마치 사실인 것처럼 생성하는 현상

---

## A-Z

**AGI (Artificial General Intelligence)**
: 인간 수준의 범용 인공지능

**API (Application Programming Interface)**
: AI 모델을 외부 프로그램에서 호출할 수 있게 하는 인터페이스

**Attention**
: 입력의 특정 부분에 집중하여 처리하는 메커니즘

**Batch**
: 한 번에 처리되는 데이터 묶음

**Chain of Thought (CoT)**
: 단계별 추론을 유도하는 프롬프팅 기법

**Constitutional AI**
: Anthropic이 개발한 AI 안전성 향상 기법

**Diffusion Model**
: 노이즈에서 점진적으로 이미지를 생성하는 모델 (예: Stable Diffusion, DALL-E)

**Embedding**
: 텍스트/이미지를 벡터로 변환한 수치 표현

**Few-shot Learning**
: 몇 가지 예시를 제공하여 AI의 응답 패턴을 유도하는 기법

**Foundation Model**
: 다양한 작업에 적용 가능한 대규모 사전 학습 모델

**GPT (Generative Pre-trained Transformer)**
: OpenAI가 개발한 생성형 언어 모델 시리즈

**RLHF (Reinforcement Learning from Human Feedback)**
: 인간 피드백을 통해 AI를 학습시키는 방법

**Temperature**
: AI 출력의 무작위성을 조절하는 파라미터 (0=결정적, 1=창의적)

**Top-k / Top-p**
: 다음 토큰 선택 시 고려할 후보의 범위를 제한하는 파라미터

**Transfer Learning**
: 한 작업에서 학습한 지식을 다른 작업에 적용하는 기법

**Zero-shot**
: 예시 없이 AI가 직접 작업을 수행하는 방식

