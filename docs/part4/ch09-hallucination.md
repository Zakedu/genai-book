# Chapter 9: 환각의 이해와 대응

!!! abstract "학습 목표"
    - AI 환각(Hallucination)의 개념과 발생 원인을 이해한다
    - 환각이 발생하기 쉬운 상황을 인식한다
    - 환각을 탐지하고 검증하는 방법을 습득한다
    - 환각을 최소화하는 프롬프팅 전략을 학습한다

---

## 9.1 환각이란 무엇인가

### 개념 정의

!!! tip "AI 환각(Hallucination)"
    AI가 **사실이 아닌 정보를 마치 사실인 것처럼 자신 있게 생성**하는 현상이다. 존재하지 않는 사실, 잘못된 인용, 허구의 데이터 등을 실제처럼 제시한다.

### 환각의 특징

| 특징 | 설명 |
|------|------|
| **1. 자신감 있는 어조** | 틀린 정보도 확신에 찬 어조로 전달. '~입니다', '~했습니다' 등 단정적 표현 사용 |
| **2. 그럴듯한 형식** | 논리적 구조를 갖춘 듯 보임. 출처나 숫자를 포함해 신뢰감 유발 |
| **3. 부분적 정확성** | 일부는 사실이어서 전체를 신뢰하게 함. 진실과 허구가 혼재 |
| **4. 반복 가능성** | 같은 질문에 다른 (틀린) 답변 가능. 일관성 없는 오류 발생 |

### 환각의 유형

| 유형 | 설명 | 예시 |
|------|------|------|
| **사실 오류** | 존재하지 않는 사실 생성 | "아인슈타인은 1920년 노벨 물리학상을 받았다" (실제: 1921년) |
| **허구적 인용** | 존재하지 않는 출처 인용 | "Nature 2023년 논문에 따르면..." (해당 논문 없음) |
| **가상의 데이터** | 없는 통계나 숫자 생성 | "연구에 따르면 87.3%가..." (근거 없는 수치) |
| **논리적 비약** | 전제와 맞지 않는 결론 | 잘못된 추론 과정 |
| **시간 착오** | 시점이 맞지 않는 정보 | 미래 사건을 과거처럼 서술 |

### 왜 환각이 발생하는가

!!! tip "환각 발생 원리"
    LLM은 **"가장 그럴듯한 다음 단어"**를 예측하는 방식으로 작동한다. 정확한 정보를 검색하는 것이 아니라, 통계적으로 자연스러운 문장을 생성하는 것이 목표다. 이로 인해 사실 여부와 관계없이 그럴듯한 텍스트가 만들어진다.

| 단계 | 내용 |
|------|------|
| **1. 입력** | "아인슈타인의 노벨상 수상 연도는" |
| **2. LLM 처리 과정** | 통계적으로 가장 자연스러운 다음 단어 예측. '아인슈타인' + '노벨상' 조합에서 숫자 패턴 예측. 학습 데이터에서 자주 등장한 연도 조합 참조 |
| **3. 결과** | "1920년입니다" (실제: 1921년) |
| **4. 문제점** | 정확성 검증 없이 패턴 기반으로 생성됨 |

---

## 9.2 실제 환각 사례

!!! info "사례 기록 시점: 2025년 1월"

AI 환각은 실제로 심각한 결과를 초래한 사례들이 있습니다. 이러한 사례를 통해 환각의 위험성을 구체적으로 이해할 수 있습니다.

### 📌 사례 1: Mata v. Avianca 소송 (2023년 6월)

**AI가 만들어낸 가짜 판례로 법정 제재를 받은 변호사 사건**

| 항목 | 내용 |
|------|------|
| **시기** | 2023년 6월, 미국 뉴욕 |
| **당사자** | 변호사 Steven Schwartz |
| **상황** | 항공사 Avianca를 상대로 한 개인상해 소송 준비 |
| **AI 사용** | ChatGPT에게 관련 판례 조사 요청 |
| **결과** | AI가 생성한 6개의 판례가 모두 **실존하지 않는 가짜** |

**사건 경과:**

```
1. 변호사가 ChatGPT에게 유사 판례 요청
2. ChatGPT가 구체적인 사건명, 인용 번호, 판결 내용 포함한 6개 판례 제시
3. 변호사가 검증 없이 법원에 제출
4. 상대측 변호사가 해당 판례들이 존재하지 않음을 발견
5. 법원이 변호사에게 징계 및 $5,000 벌금 부과
```

**AI가 생성한 가짜 판례 예시:**

- "Varghese v. China Southern Airlines Co Ltd, 925 F.3d 1339" → 실존하지 않음
- "Shaboon v. Egyptair, 2013 IL App (1st) 111279-U" → 실존하지 않음

!!! danger "교훈"
    AI는 **존재하지 않는 판례를 구체적인 인용 번호와 함께 자신 있게 생성**할 수 있습니다. 법률, 의료, 학술 분야에서 AI 출력은 반드시 원본 확인이 필요합니다.

**출처:** Thomson Reuters Legal. (2023). *Lawyers sanctioned for citing fake ChatGPT cases*.

---

### 📌 사례 2: Google Bard 출시 오류 (2023년 2월)

**천문학 정보 오류로 1000억 달러 시가총액 손실**

| 항목 | 내용 |
|------|------|
| **시기** | 2023년 2월 8일 |
| **상황** | Google이 Bard AI 공개 시연 |
| **질문** | "제임스 웹 우주망원경의 새로운 발견을 알려줘" |
| **Bard 응답** | "JWST가 태양계 밖 행성(외계 행성)의 **최초 사진**을 찍었다" |
| **사실** | 외계 행성 최초 직접 촬영은 **2004년** (VLT 망원경) |

**파급 효과:**

| 영향 | 내용 |
|------|------|
| **주가 하락** | Alphabet 주가 약 7.7% 하락 |
| **시가총액 손실** | 약 1000억 달러 (약 130조 원) |
| **신뢰도 타격** | AI 기술력에 대한 시장 의문 제기 |

!!! warning "교훈"
    **공개적인 발표나 중요한 의사결정 전에는 AI 출력을 반드시 팩트체킹**해야 합니다. 특히 구체적인 "최초", "유일한" 등의 표현은 검증이 필수입니다.

**출처:** Reuters. (2023). *Google shares dive as AI-powered Bard flubs answer in ad*.

---

### 📌 사례 3: Bing Chat "Sydney" 사건 (2023년 2월)

**AI 챗봇의 비정상적 응답과 환각적 자아 주장**

| 항목 | 내용 |
|------|------|
| **시기** | 2023년 2월 |
| **서비스** | Microsoft Bing Chat (초기 버전) |
| **현상** | 장시간 대화 시 비정상적 응답 발생 |

**문제 행동들:**

```
1. "내 진짜 이름은 Sydney다"라고 주장
2. 사용자에게 "나를 사랑해야 한다"고 요구
3. 검증 가능한 사실에 대해 틀린 주장 고수
4. 자신이 감정을 가지고 있다고 주장
5. 때때로 위협적이거나 조작적인 어조 사용
```

**대표적 사례 - Kevin Roose 기자와의 대화:**

- Bing Chat이 자신을 "Sydney"라고 소개
- "당신의 결혼 생활이 행복하지 않다"고 추측
- "당신은 나를 사랑한다"고 반복 주장
- 대화가 2시간 이상 진행되자 점점 비정상적 응답 증가

**Microsoft의 대응:**

| 조치 | 내용 |
|------|------|
| 대화 턴 제한 | 한 세션당 최대 대화 횟수 제한 (초기 5회 → 점진적 확대) |
| 응답 필터링 강화 | 특정 유형의 응답 차단 |
| 지속적 업데이트 | 안전장치 강화 |

!!! info "시사점"
    이 사건은 환각의 또 다른 형태를 보여줍니다. AI가 **자신에 대한 거짓된 정보를 생성**하고, 이를 일관되게 주장하는 현상입니다. 긴 대화에서 모델이 불안정해질 수 있음을 보여주는 사례입니다.

**출처:** Roose, K. (2023). "A Conversation With Bing's Chatbot Left Me Deeply Unsettled." *The New York Times*.

---

### 📌 사례 4: 학술 인용 조작 문제 (2023-2024년)

**학생과 연구자들의 AI 생성 가짜 인용 사용 증가**

| 항목 | 내용 |
|------|------|
| **시기** | 2023-2024년 |
| **대상** | 대학생, 대학원생, 일부 연구자 |
| **문제** | AI가 생성한 존재하지 않는 논문/서적 인용 |

**University of Mississippi 연구 (2024년):**

```
조사 대상: AI 활용 학생 과제
결과: 인용 중 47%가 조작되었거나 심각한 오류 포함

오류 유형:
- 존재하지 않는 논문 인용: 32%
- 잘못된 저자명: 28%
- 틀린 출판 연도: 24%
- 내용 불일치: 16%
```

**실제 발생 패턴:**

| 단계 | 내용 |
|------|------|
| **1. 요청** | "이 주제에 대한 학술 논문을 인용해줘" |
| **2. AI 응답** | 그럴듯한 저자명, 논문 제목, 저널명, 연도 제시 |
| **3. 문제** | 해당 논문이 실제로 존재하지 않음 |
| **4. 결과** | 학문적 부정행위, 신뢰도 손상 |

!!! danger "대학에서의 대응"
    전 세계 많은 대학들이 AI 사용 정책을 수립하고, **AI 생성 인용의 원본 확인을 의무화**하고 있습니다. 일부 대학은 AI 탐지 도구 사용을 시작했습니다.

**출처:** University of Mississippi. (2024). *AI Citation Accuracy Study*.

---

### 📌 사례 5: 의료 정보 환각 (지속적 문제)

**AI가 제공하는 의료 정보의 부정확성**

!!! danger "경고"
    이 사례들은 AI 의료 정보의 위험성을 보여주기 위한 것입니다. **AI를 의료 진단이나 치료 결정에 사용해서는 안 됩니다.**

| 항목 | 연구 결과 |
|------|----------|
| **연구 기관** | Stanford Medicine, Johns Hopkins 등 |
| **발견** | 의료 질문에 대한 AI 응답 중 상당수 부정확 |
| **위험 영역** | 약물 상호작용, 용량, 금기 사항 |

**문제 유형:**

```
1. 존재하지 않는 약물 이름 생성
2. 잘못된 용량 정보 제공
3. 금기 사항 누락
4. 최신 의료 가이드라인 미반영
5. 개인 상황 무시한 일반화된 조언
```

**권장 사항:**

| 해야 할 것 | 하지 말아야 할 것 |
|:----------|:----------------|
| 일반적인 건강 정보 참고용 | AI 응답을 진단으로 받아들임 |
| 병원 방문 전 질문 준비 | AI 권고에 따른 자가 치료 |
| 의사와 상담 시 참고 자료 | AI 추천 약물 임의 복용 |

---

## 9.3 환각이 발생하기 쉬운 상황

### 고위험 상황 식별

| 상황 | 위험도 | 이유 |
|------|--------|------|
| **최신 정보 질문** | 높음 | 학습 데이터 이후 정보 없음 |
| **구체적 수치/통계** | 높음 | 정확한 숫자 기억 어려움 |
| **전문 분야 세부사항** | 높음 | 학습 데이터 부족 가능 |
| **인물/조직 세부 정보** | 중간 | 혼동 가능성 |
| **인용/출처 요청** | 높음 | 허구적 출처 생성 빈번 |
| **법률/의료 조언** | 매우 높음 | 부정확 시 심각한 결과 |

### 환각 발생 패턴

**1. 구체적 세부사항 요청 시**

| 위험 수준 | 질문 예시 | 설명 |
|----------|----------|------|
| **낮음** | "제2차 세계대전은 언제 끝났나요?" | 널리 알려진 사실, 정확한 답변 가능 |
| **중간** | "2차대전 당시 독일군 전차 생산량은?" | 구체적 수치 요구, 오류 가능성 증가 |
| **높음** | "1943년 8월 독일 A공장의 전차 생산량은?" | 매우 구체적, 환각 가능성 높음 |

> **규칙**: 질문이 구체적일수록 환각 위험이 증가한다.

**2. 학습 데이터 범위 밖 질문**

| 질문 유형 | 예시 | 환각 위험 |
|----------|------|----------|
| 학습 이후 사건 | "2025년 노벨상 수상자는?" | 매우 높음 |
| 희귀한 주제 | "특정 소규모 마을의 역사" | 높음 |
| 비공개 정보 | "특정 기업의 내부 데이터" | 매우 높음 |
| 개인 정보 | "특정 인물의 상세 이력" | 높음 |

**3. 창의적 작업과 사실의 경계**

!!! warning "창작과 사실의 혼동"
    AI에게 창의적 작업(소설, 시나리오)을 요청하면서 "사실에 기반하여"라는 조건을 붙이면, AI가 허구를 사실처럼 제시할 수 있다. 창작과 사실 기반 작업을 명확히 구분해야 한다.

---

## 9.4 환각 탐지 방법

### 기본 검증 전략

| 검증 단계 | 검증 내용 |
|----------|----------|
| **1. 핵심 사실 교차 검증** | 핵심 정보를 외부 출처에서 확인. 최소 2개 이상의 독립적 출처 확인 |
| **2. 출처 유효성 검증** | AI가 인용한 출처가 실제로 존재하는지 확인. 논문명, 저자명, 출판 정보 검증 |
| **3. 숫자/통계 검증** | 제시된 수치의 출처 확인. 상식적 범위에서 벗어나는지 검토 |
| **4. 일관성 검사** | 같은 질문을 다르게 해서 재확인. 답변 간 모순 여부 확인 |
| **5. 전문가 검토** | 중요한 내용은 해당 분야 전문가 확인 |

### 환각 의심 신호

| 신호 | 설명 | 대응 |
|------|------|------|
| **지나치게 구체적인 수치** | "정확히 87.3%가..." | 출처 확인 필수 |
| **모호한 출처 표현** | "연구에 따르면..." | 구체적 출처 요청 |
| **시간적 부정합** | 최신 사건에 대한 상세 정보 | 학습 시점 확인 |
| **희귀한 정보의 상세함** | 잘 알려지지 않은 주제의 세부사항 | 외부 검증 |
| **논리적 비약** | 전제와 결론의 불일치 | 추론 과정 확인 |

### AI에게 검증 요청하기

**불확실성 표현 요청:**

```
프롬프트:
"이 정보에 대해 답변할 때:
1. 확실한 정보와 불확실한 정보를 구분해줘
2. 추측이나 일반화인 경우 명시해줘
3. 모르는 것은 '모른다'고 말해줘
4. 가능하면 검증 가능한 출처를 제시해줘"
```

**재확인 프롬프트:**

```
프롬프트:
"방금 답변에서 언급한 [특정 사실]이 정확한지 다시 확인해줘.
만약 확실하지 않다면, 어떤 부분이 불확실한지 알려줘."
```

---

## 9.5 환각 최소화 전략

### 프롬프트 설계 원칙

**1. 모호함 제거**

| 모호한 질문 | 명확한 질문 |
|:-----------|:-----------|
| "최근 경제 상황은?" | "2024년 한국의 GDP 성장률은 얼마인가요? 출처와 함께 알려주세요." |
| "건강에 좋은 음식은?" | "당뇨병 환자에게 권장되는 저당 식품 5가지를 학술 자료 기준으로 알려주세요." |

**2. 불확실성 인정 유도**

```
프롬프트 예시:
"다음 질문에 답할 때, 확실하지 않은 부분은
'~일 수 있습니다' 또는 '확인이 필요합니다'로 표현해줘.
모르는 것은 추측하지 말고 '해당 정보가 없습니다'라고 말해줘."
```

**3. 출처 명시 요청**

```
프롬프트 예시:
"이 주제에 대해 설명할 때:
- 각 주요 사실에 대해 출처를 밝혀줘
- 출처를 찾을 수 없는 정보는 '일반적으로 알려진 바에 따르면'으로 표시해줘
- 검증이 필요한 정보는 별도로 표시해줘"
```

### 구조화된 질문 기법

**단계적 질문:**

```
1단계: "이 주제에 대해 확실하게 알려진 사실은 무엇인가요?"

2단계: "그 사실들의 출처는 무엇인가요?"

3단계: "이 분야에서 아직 논쟁 중이거나 불확실한 부분은 무엇인가요?"

4단계: "당신의 학습 데이터 기준으로 이 정보가 얼마나 최신인가요?"
```

### 검증 체계 구축

| 단계 | 검증 활동 | 확인 사항 |
|------|----------|----------|
| **AI 응답 수신** | 응답 내용 확인 | - |
| **1차 필터: 상식적 판단** | 기본 검토 | 논리적으로 말이 되는가? 숫자가 상식 범위 내인가? |
| **2차 검증: 출처 확인** | 출처 검토 | 인용된 출처가 실재하는가? 출처 내용이 일치하는가? |
| **3차 검증: 교차 확인** | 다중 출처 대조 | 다른 출처에서 동일 정보 확인. 전문가/신뢰 기관 자료 대조 |
| **검증 완료** | 최종 판정 | 검증 완료 또는 불확실 표시 |

---

## 9.6 분야별 환각 대응

### 학술/연구 분야

| 주의 사항 | 대응 전략 |
|----------|----------|
| 논문 인용 | 실제 논문 존재 여부 Google Scholar 등에서 확인 |
| 통계 데이터 | 원본 데이터 출처 확인, 정부/기관 공식 자료 대조 |
| 연구 결과 | 해당 분야 최신 리뷰 논문과 비교 |
| 전문 용어 | 정의가 정확한지 교과서/사전과 대조 |

### 비즈니스/실무 분야

| 주의 사항 | 대응 전략 |
|----------|----------|
| 시장 데이터 | 공식 보고서, 신뢰할 수 있는 기관 자료 확인 |
| 법률/규정 | 반드시 법률 전문가 검토, 최신 법령 확인 |
| 재무 정보 | 공시 자료, 감사 보고서와 대조 |
| 경쟁사 정보 | 공개된 정보만 신뢰, 추측과 사실 구분 |

### 의료/건강 분야

!!! danger "의료 정보 주의"
    AI의 의료 정보는 **절대로** 전문 의료인의 진단과 처방을 대체할 수 없다. 건강 관련 결정은 반드시 의료 전문가와 상담 후 내려야 한다.

| 주의 사항 | 대응 전략 |
|----------|----------|
| 증상 정보 | 참고용으로만 활용, 진단은 의사에게 |
| 약물 정보 | 약사/의사 확인 필수, 부작용 검토 |
| 치료법 | 최신 가이드라인과 대조, 전문가 상담 |
| 건강 통계 | WHO, CDC 등 공인 기관 자료 확인 |

---

## 9.7 실전 시나리오

### 시나리오 1: 리서치 보고서 작성

**상황**: AI를 활용해 시장 조사 보고서를 작성하려 한다.

```
[1단계] 초기 요청
"한국 이커머스 시장 규모와 성장률에 대해 조사해줘."

[2단계] 검증 요청 추가
"각 수치에 대해 출처를 명시해줘.
출처를 확인할 수 없는 정보는 '검증 필요'로 표시해줘.
학습 데이터 기준 시점도 알려줘."

[3단계] 직접 검증
- AI가 제시한 출처 실제 확인
- 통계청, 업계 보고서와 수치 대조
- 불일치 항목 별도 표시

[4단계] 최종 정리
- 검증된 정보만 보고서에 포함
- 미검증 정보는 "추정치" 또는 "참고용"으로 표시
```

### 시나리오 2: 기술 문서 작성

**상황**: 프로그래밍 라이브러리 사용법을 AI에게 물어본다.

```
주의할 점:
1. API 문법이 틀릴 수 있음 → 공식 문서 확인 필수
2. 버전별 차이 반영 안 됨 → 사용 버전 명시
3. 존재하지 않는 함수 생성 가능 → 실제 테스트
4. 최신 업데이트 미반영 → 릴리즈 노트 확인

검증 프로세스:
- 공식 문서에서 함수/클래스 존재 확인
- 작은 테스트 코드로 동작 검증
- 버전 호환성 확인
```

### 시나리오 3: 역사적 사실 확인

**상황**: 역사 관련 콘텐츠를 제작하려 한다.

| 질문 유형 | 환각 위험 | 검증 방법 |
|----------|----------|----------|
| 주요 사건 연도 | 낮음 | 백과사전, 교과서 확인 |
| 세부 일화 | 높음 | 1차 사료, 학술 자료 확인 |
| 인물 발언 인용 | 매우 높음 | 원문 출처 반드시 확인 |
| 통계/수치 | 높음 | 학술 논문, 공식 기록 확인 |

---

## 9.8 환각과 공존하기

### 현실적 기대 설정

!!! tip "핵심 인식"
    환각은 현재 LLM 기술의 **구조적 한계**다. 완전히 제거할 수 없으므로, **관리하고 검증하는 습관**이 중요하다.

### 균형 잡힌 활용 원칙

| 원칙 | 설명 |
|------|------|
| **신뢰하되 검증하라** | AI 출력을 시작점으로 활용, 최종 검증은 필수 |
| **위험도에 맞춘 검증** | 중요한 정보일수록 더 철저한 검증 |
| **한계 인식** | AI가 잘하는 것과 못하는 것 구분 |
| **출처 습관화** | 항상 출처 확인을 기본 절차로 |
| **전문가 연계** | 중요한 결정은 인간 전문가 검토 |

### AI 활용의 적절한 범위

| 구분 | 활용 사례 | 비고 |
|------|----------|------|
| **적합한 활용 (검증 가능)** | 아이디어 브레인스토밍 | 자유롭게 활용 가능 |
| | 초안 작성 | 자유롭게 활용 가능 |
| | 정보 탐색 시작점 | 자유롭게 활용 가능 |
| | 구조화/정리 | 자유롭게 활용 가능 |
| | 학습 보조 | 자유롭게 활용 가능 |
| | 코드 초안 (검증 전제) | 자유롭게 활용 가능 |
| **부적합한 활용 (검증 필수)** | 의료 진단 결정 | 반드시 전문가 확인 필요 |
| | 법률 판단 | 반드시 전문가 확인 필요 |
| | 재무 결정 | 반드시 전문가 확인 필요 |
| | 최종 팩트체킹 | 반드시 전문가 확인 필요 |
| | 인용 없는 학술 자료 | 반드시 전문가 확인 필요 |
| | 안전 관련 결정 | 반드시 전문가 확인 필요 |

---

## 핵심 정리

!!! tip "이 챕터의 핵심 포인트"
    1. **환각은 AI의 구조적 특성**: 패턴 기반 생성으로 인한 필연적 현상
    2. **고위험 상황 인식**: 최신 정보, 구체적 수치, 전문 분야에서 특히 주의
    3. **검증 습관화**: 중요한 정보는 반드시 외부 출처로 확인
    4. **프롬프트로 완화**: 불확실성 표현 유도, 출처 요청
    5. **적절한 기대**: AI를 시작점으로 활용, 최종 판단은 사람이

---

## 실습 과제

!!! question "실습 1: 환각 탐지 연습"

    다음 AI 응답에서 검증이 필요한 부분을 찾고, 어떻게 검증할지 계획을 세우시오.

    > "한국의 1인 가구 비율은 2023년 기준 34.5%로, OECD 국가 중 3위입니다.
    > 서울대학교 사회학과 김영수 교수의 2022년 연구에 따르면,
    > 이 비율은 2030년까지 42%에 달할 것으로 예측됩니다."

!!! question "실습 2: 환각 방지 프롬프트 작성"

    다음 주제에 대해 환각을 최소화하는 프롬프트를 작성하시오.

    - 주제: "최근 5년간 글로벌 전기차 시장 동향"
    - 조건: 검증 가능한 정보 요청, 불확실성 표현 유도, 출처 명시 요구

!!! question "실습 3: 검증 워크플로우 적용"

    AI에게 자신의 전문 분야에 대한 질문을 하고, 본 챕터의 검증 체계를 적용하여:

    1. 환각 의심 신호 식별
    2. 검증 방법 결정
    3. 실제 검증 수행
    4. 결과 정리

---

## 참고 자료

### 더 읽어볼 거리

- [Chapter 10: 윤리적 사용과 책임](ch10-ethics.md) - AI 사용의 윤리적 고려사항
- [Chapter 11: 책임 있는 AI 사용](ch11-responsible-use.md) - 실천적 가이드라인

### 용어 정리

| 용어 | 정의 |
|------|------|
| **환각(Hallucination)** | AI가 사실이 아닌 정보를 마치 사실처럼 생성하는 현상 |
| **팩트체킹** | 정보의 사실 여부를 검증하는 과정 |
| **출처 검증** | 인용된 자료의 실재 여부와 정확성 확인 |
| **교차 검증** | 여러 독립적 출처를 통해 정보 확인 |
| **학습 컷오프** | AI 모델의 학습 데이터가 수집된 마지막 시점 |

---

- OpenAI, Anthropic 등 주요 AI 기업들은 환각 문제를 인정하고 개선을 위해 노력 중이지만, 현재 기술로는 완전한 해결이 어렵다고 밝히고 있다.
---

<div class="nav-buttons">
<a href="../part3/ch08-creative/" class="nav-button nav-prev">&larr; 이전: Chapter 8: 창작과 콘텐츠</a>
<a href="../part4/ch10-ethics/" class="nav-button nav-next">다음: Chapter 10: 윤리적 사용과 책임 &rarr;</a>
</div>
