# Chapter 1: 생성형 AI란 무엇인가

!!! abstract "학습 목표"
    - AI, 머신러닝, 생성형 AI의 관계를 명확히 구분할 수 있다
    - LLM의 "다음 토큰 예측" 원리를 이해하고 설명할 수 있다
    - 생성형 AI가 할 수 있는 것과 할 수 없는 것을 구분할 수 있다
    - 생성형 AI의 한계를 인식하고 적절한 기대치를 설정할 수 있다

---

## 1. AI의 계층 구조

### AI, 머신러닝, 딥러닝, 생성형 AI의 관계

이 용어들은 종종 혼용되지만, 실제로는 **포함 관계**를 가집니다.

**AI 기술의 포함 관계**

| 계층 | 기술 | 설명 |
|:---:|:---|:---|
| 1 | **인공지능 (AI)** | 인간의 지능을 모방하는 모든 기술 |
| 2 | ↳ **머신러닝 (ML)** | 데이터로부터 패턴을 학습하는 AI |
| 3 | &nbsp;&nbsp;↳ **딥러닝** | 인공 신경망을 사용한 머신러닝 |
| 4 | &nbsp;&nbsp;&nbsp;&nbsp;↳ **생성형 AI** | 새로운 콘텐츠를 생성하는 딥러닝 |

### 각 개념의 정의

| 개념 | 정의 | 예시 |
|------|------|------|
| **인공지능 (AI)** | 인간의 지능을 모방하는 모든 기술 | 체스 프로그램, 음성 인식, 자율주행 |
| **머신러닝 (ML)** | 명시적 프로그래밍 없이 데이터에서 학습 | 스팸 필터, 추천 시스템 |
| **딥러닝** | 다층 신경망을 사용한 머신러닝 | 이미지 인식, 음성 합성 |
| **생성형 AI** | 새로운 콘텐츠를 생성하는 AI | ChatGPT, DALL-E, Midjourney |

!!! tip "핵심 구분"
    전통적인 AI는 **분류·예측**에 집중했다면, 생성형 AI는 **새로운 콘텐츠 창조**에 초점을 맞춥니다.

### 전통적 AI vs 생성형 AI

| 구분 | 전통적 AI | 생성형 AI |
|------|----------|----------|
| **목적** | 분류, 예측, 탐지 | 콘텐츠 생성 |
| **입력** | 데이터 → 라벨/숫자 | 프롬프트 → 콘텐츠 |
| **출력** | "이것은 고양이다" (분류) | "고양이에 관한 시를 써드립니다" (생성) |
| **예시** | 스팸 필터, 신용 점수 | ChatGPT, DALL-E |

---

## 2. 대규모 언어 모델(LLM)의 작동 원리

### LLM이란?

**LLM(Large Language Model, 대규모 언어 모델)**은 방대한 양의 텍스트 데이터를 학습하여 인간의 언어를 이해하고 생성할 수 있는 AI 모델입니다.

| 모델 | 개발사 | 파라미터 수 |
|------|--------|-----------|
| GPT-4 | OpenAI | 추정 1조+[^1] |
| Claude 3 | Anthropic | 비공개[^2] |
| Gemini | Google | 비공개[^3] |
| Llama 3 | Meta | 700억~4050억 |

!!! info "파라미터란?"
    파라미터는 모델이 학습 과정에서 조정하는 **가중치**입니다. 파라미터가 많을수록 더 복잡한 패턴을 학습할 수 있지만, 그것이 곧 "더 똑똑하다"를 의미하지는 않습니다.

### 핵심 원리: 다음 토큰 예측

!!! tip "LLM의 본질"
    LLM은 본질적으로 **"다음에 올 단어(토큰)를 예측하는 기계"**입니다. 사실을 "알고 있는" 것이 아니라, 학습한 패턴을 기반으로 가장 그럴듯한 다음 단어를 예측합니다.

#### 토큰(Token)이란?

**토큰**은 LLM이 텍스트를 처리하는 기본 단위입니다. 단어 전체일 수도 있고, 단어의 일부일 수도 있습니다.

| 언어 | 토큰화 예시 | 토큰 수 |
|------|-----------|--------|
| 영어 | "Hello, world!" → ["Hello", ",", " world", "!"] | 4 |
| 한국어 | "안녕하세요" → ["안녕", "하세요"] 또는 ["안", "녕", "하", "세", "요"] | 2~5 |

!!! tip "토큰과 비용"
    대부분의 AI 서비스는 **토큰 수**를 기준으로 요금을 부과합니다. 한국어는 영어보다 같은 의미를 전달하는 데 더 많은 토큰이 필요한 경향이 있습니다.

#### 예측 과정 시각화

**입력**: "오늘 날씨가 정말"

**다음 단어 예측 과정**

| 입력 문장 | 예측 단어 | 확률 |
|:---|:---|:---:|
| "오늘 날씨가 정말" | 좋다 | 35% |
| | 덥다 | 25% |
| | 춥다 | 20% |
| | 맑다 | 15% |
| | 흐리다 | 5% |

→ **"좋다"** 선택 후 다음 단어 예측 반복...

이 과정이 수백, 수천 번 반복되어 하나의 문장, 문단, 글이 완성됩니다.

### 학습 데이터의 역할

LLM은 **인터넷의 방대한 텍스트**를 학습합니다.

| 학습 데이터 출처 | 포함 내용 |
|-----------------|----------|
| 웹페이지 | 뉴스, 블로그, 위키피디아 |
| 도서 | 소설, 학술서, 기술 문서 |
| 코드 | GitHub 등 오픈소스 저장소 |
| 대화 | 포럼, Q&A 사이트 |

!!! warning "학습 데이터의 한계"
    1. **학습 시점 이후의 정보는 모름**: 2023년에 학습이 끝난 모델은 2024년 뉴스를 알 수 없습니다.
    2. **학습 데이터의 편향 반영**: 인터넷에 많은 정보가 더 잘 학습됩니다.
    3. **잘못된 정보도 학습**: 인터넷의 오류 정보도 함께 학습됩니다.

---

## 3. 생성형 AI가 할 수 있는 것

### 강점 영역

| 영역 | 설명 | 예시 |
|------|------|------|
| **텍스트 생성** | 다양한 스타일의 글 작성 | 이메일, 보고서, 블로그, 소설 |
| **요약** | 긴 문서를 핵심만 추출 | 논문 요약, 회의록 정리 |
| **번역** | 다국어 간 번역 | 영한 번역, 다국어 지원 |
| **코드 작성** | 프로그래밍 코드 생성 | Python, JavaScript 등 |
| **아이디어 발상** | 브레인스토밍 지원 | 마케팅 아이디어, 제목 후보 |
| **형식 변환** | 데이터 형태 변환 | JSON→표, 텍스트→목록 |
| **질문 응답** | 지식 기반 답변 | 개념 설명, 비교 분석 |

### 📌 사례: 효과적인 활용 예시

#### 사례 1: 이메일 초안 작성

| 사람이 직접 작성 (30분 소요) | AI 활용 (5분 소요) |
|:---------------------------|:------------------|
| 빈 화면에서 시작하여 구조를 잡고, 표현을 다듬고, 톤을 조절하는 데 상당한 시간이 소요됩니다. | 프롬프트로 초안을 생성하고, 이를 검토·수정하여 완성합니다. 시간을 80% 이상 절약할 수 있습니다. |

#### 사례 2: 개념 학습

```
프롬프트: "양자컴퓨터를 고등학생도 이해할 수 있게 설명해줘"

→ AI는 복잡한 개념을 다양한 수준으로 설명할 수 있습니다.
→ 비유, 예시를 풍부하게 제공합니다.
→ 단, 최신 연구 결과나 세부 기술 스펙은 검증이 필요합니다.
```

---

## 4. 생성형 AI가 할 수 없는 것

### 근본적 한계

!!! tip "핵심 인식"
    생성형 AI는 **"사실을 아는 것"이 아니라 "그럴듯한 텍스트를 생성하는 것"**입니다. 이 구분을 이해하는 것이 올바른 AI 활용의 첫걸음입니다.

### 한계 목록

| 한계 | 설명 | 결과 |
|------|------|------|
| **사실 검증 불가** | 진위를 판단하는 메커니즘 없음 | 환각(Hallucination) 발생 |
| **실시간 정보 부재** | 학습 시점 이후 정보 없음 | 최신 뉴스, 주가 등 답변 불가 |
| **수학적 추론 한계** | 복잡한 계산에서 오류 발생 | 다단계 수학 문제에서 실수 |
| **개인 정보 부재** | 사용자 개인 맥락 모름 | "내 일정"을 알 수 없음 |
| **물리적 행동 불가** | 디지털 텍스트만 생성 | 실제 예약, 결제 직접 수행 불가 |
| **인과관계 이해 한계** | 상관관계를 인과로 오해 가능 | 논리적 추론 오류 |

### 📌 사례: 환각(Hallucination)의 실제

#### 사례 1: Mata v. Avianca (2023)

뉴욕의 변호사가 ChatGPT를 사용해 법률 조사를 수행했습니다.[^4]

| 항목 | 내용 |
|------|------|
| **상황** | 변호사가 AI에게 관련 판례를 요청 |
| **AI 응답** | 6개의 판례를 상세히 인용 |
| **문제** | 6개 판례 모두 **실존하지 않는 가짜** |
| **결과** | 법원으로부터 징계, 벌금 부과 |
| **교훈** | AI 출력은 반드시 원본 확인 필요 |

!!! danger "핵심 교훈"
    AI는 "모른다"고 말하는 대신, **그럴듯한 거짓 정보를 생성**할 수 있습니다. 이것이 환각(Hallucination)입니다.

#### 사례 2: Google Bard 런칭 실수 (2023)

| 항목 | 내용 |
|------|------|
| **상황** | Google이 Bard 시연 중 천문학 질문에 답변 |
| **AI 응답** | "제임스 웹 우주망원경이 최초로 외계 행성 사진 촬영" |
| **사실** | 최초 촬영은 2004년 (다른 망원경) |
| **결과** | Alphabet 주가 하락, 약 1000억 달러 손실 |
| **교훈** | 공개 발표 전 팩트체킹 필수 |

---

## 5. 올바른 기대치 설정

### AI를 바라보는 관점

| ❌ 잘못된 인식 | ✅ 올바른 인식 |
|:--------------|:--------------|
| "AI는 모든 것을 안다" | "AI는 패턴을 학습했을 뿐이다" |
| "AI 답변은 믿을 수 있다" | "AI 답변은 검증이 필요하다" |
| "AI가 나 대신 해준다" | "AI는 나의 도구이다" |
| "AI는 창의적이다" | "AI는 학습한 것을 재조합한다" |

### 효과적인 AI 활용을 위한 원칙

| 원칙 | 설명 |
|------|------|
| **1. 초안 도구로 활용** | 최종 결과가 아닌 시작점으로 사용 |
| **2. 항상 검증** | 중요한 사실은 반드시 교차 확인 |
| **3. 맥락 제공** | AI에게 충분한 배경 정보 제공 |
| **4. 반복 개선** | 한 번에 완벽한 결과 기대하지 않기 |
| **5. 한계 인식** | AI가 잘하는 것과 못하는 것 구분 |

---

## 6. 생성형 AI의 다양한 유형

### 모달리티별 분류

| 유형 | 입력 | 출력 | 대표 도구 |
|------|------|------|----------|
| **텍스트 생성** | 텍스트 | 텍스트 | ChatGPT, Claude, Gemini |
| **이미지 생성** | 텍스트 | 이미지 | DALL-E, Midjourney, Stable Diffusion |
| **음성 생성** | 텍스트 | 음성 | ElevenLabs, VALL-E |
| **영상 생성** | 텍스트 | 영상 | Sora, Runway |
| **음악 생성** | 텍스트 | 음악 | Suno, Udio |
| **멀티모달** | 텍스트+이미지 | 텍스트+이미지 | GPT-4o, Gemini 1.5 |

### 멀티모달 AI의 등장

!!! tip "멀티모달(Multimodal)"
    텍스트, 이미지, 음성 등 **여러 형태의 데이터를 동시에 이해하고 생성**할 수 있는 AI입니다. 2024년 이후 주요 트렌드입니다.

**멀티모달 AI 입출력 예시**

| 입력 | 멀티모달 AI | 출력 |
|:---|:---:|:---|
| 이미지 + "이게 뭐야?" | → 처리 → | "이것은 에펠탑입니다..." |
| "고양이 그림 그려줘" | → 처리 → | 고양이 이미지 |
| 음성 파일 + "요약해줘" | → 처리 → | "회의 내용 요약..." |

---

## 핵심 정리

!!! abstract "이 챕터의 핵심 포인트"
    1. **포함 관계**: AI ⊃ 머신러닝 ⊃ 딥러닝 ⊃ 생성형 AI
    2. **LLM의 본질**: "다음 토큰 예측 기계" - 사실을 아는 것이 아님
    3. **토큰**: LLM이 텍스트를 처리하는 기본 단위
    4. **강점**: 텍스트 생성, 요약, 번역, 코드 작성, 아이디어 발상
    5. **한계**: 환각(사실 오류), 실시간 정보 부재, 수학적 추론 한계
    6. **올바른 인식**: AI는 "전지적 존재"가 아닌 "확률 기반 도구"
    7. **멀티모달**: 텍스트, 이미지, 음성 등 여러 형태를 동시에 처리

---

## 생각해볼 질문

!!! question "토론 질문"

    1. LLM이 "다음 토큰을 예측하는 것"과 "진짜로 이해하는 것"의 차이는 무엇일까?
    2. AI가 생성한 콘텐츠와 인간이 만든 콘텐츠를 구분할 수 있어야 할까?
    3. 환각(Hallucination) 문제를 완전히 해결할 수 있을까?
    4. 생성형 AI가 인간의 창의성을 대체할 수 있다고 생각하는가?

---

## 관련 위키 문서

- [토큰](../wiki/concepts/token.md)
- [컨텍스트 윈도우](../wiki/concepts/context-window.md)
- [환각](../wiki/concepts/hallucination.md)
- [ChatGPT](../wiki/tools/chatgpt.md)
- [Claude](../wiki/tools/claude.md)
- [Gemini](../wiki/tools/gemini.md)

---

## 참고 자료

[^1]: OpenAI. (2023). *GPT-4 Technical Report*. https://openai.com/research/gpt-4
[^2]: Anthropic. (2024). *Claude 3 Model Card*. https://www.anthropic.com/claude
[^3]: Google. (2024). *Gemini: A Family of Highly Capable Multimodal Models*. https://deepmind.google/technologies/gemini/
[^4]: Thomson Reuters. (2023). *Mata v. Avianca: Lawyers sanctioned for using ChatGPT*.
---

<div class="nav-buttons">
<a href="/part0/ch00-why-now/" class="nav-button nav-prev">&larr; 이전: 0.2 왜 지금 배워야 하는가</a>
<a href="/part2/ch02-tools-ecosystem/" class="nav-button nav-next">다음: Chapter 2: 주요 도구와 생태계 &rarr;</a>
</div>
